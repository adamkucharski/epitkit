---
title: "Cleaning Epidemiological Data"
authors: [""]
date: '2024-07-31'
output:
  pdf_document: default
  html_document: 
    self_contained: true
  word_document: default
image: null
licenses: CC-BY
teaching: 40
exercises: 4
editor_options: 
  markdown: 
    wrap: 72
---

::: questions

- How to clean epidemiological data with R?

:::

::: objectives

At the end of this workshop you will be able to:

- Recognize the tools that facilitate the cleaning of epidemiological data.

- Identify good practices for cleaning epidemiological data.

- Explore the process of cleaning, organizing, and characterizing epidemiological data.
:::

::: prereq
This unit has the following prerequisites:

-   Introduction to R and RStudio
:::


::: checklist

### **Table of Contents**

-   Module: Data Science in Public Health 
    - Unit: Cleaning Epidemiological Data
        -   Topic 1: Introduction to Data Cleaning (See on course platform)
        -   Topic 2: Exploration and Characterization of Data
        -   Topic 3: Modification, Cleaning, and Correction of Data: Common Errors and Their Solutions
        -   Topic 4: Data Organization
    
:::

## Introduction

In this unit, we will address the process of cleaning epidemiological data, using the previous knowledge from the Introduction to R and RStudio unit. We will approach data cleaning as a fundamental process to obtain suitable inputs for data analysis, visualization, and the creation of epidemiological reports.

In this unit, you will learn to recognize the necessary activities to carry out the data cleaning process, how to solve the most common errors in databases that can affect analysis, and understand how to describe and organize data, classify variables, apply formats to variables, handle duplicate data, and address missing data.

## **Topic 2: Exploration and Characterization of Data**

### **2.2. Exploring the Structure of Data in R**

Once the exploration and characterization of the data through documentation is done, we will proceed to explore the dataset.

#### **2.2.1. Loading the Information**

::: checklist

### ⚠️ **Instructions:**

Before starting to work, make sure you have completed the following steps:

1.  Create a project in R

2.  Create a folder called "data" within the project

3.  Download the file data_limpieza.zip that contains the dataset "covid_LA.csv" and the information document "covid_LA_info.txt", available at the following link
    <https://github.com/TRACE-LAC/TRACE-LAC-data/raw/main/data_limpieza.zip> 

4.  Unzip the files and save the dataset "covid_LA.csv" in the "data" folder

5.  Create an R script
:::

::: callout
If you have any questions about the process, please return to the **Introduction to R** unit.
:::

**Expected result:** Up to this point, the project should look like this:

![](fig/vista_proyecto.png)

6.  Load the libraries: tidyverse, rio, and cleanepi.

::: callout

If you haven't installed them yet, you can do so with the following code

```{r eval = FALSE}
if(!require("tidyverse")) install.packages("tidyverse") #if you need to install tidyverse
if(!require("cleanepi")) install.packages("cleanepi") #if you need to install cleanepi
if(!require("rio")) install.packages("rio") #if you need to install rio
```

:::

```{r eval = FALSE}
library("tidyverse")
library("cleanepi")
library("rio")
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo=FALSE}
library("tidyverse")
library("cleanepi")
library("rio")
```

7.  Load the dataset

⚠️ **Instruction:** Load the dataset in R with the following code:

```{r eval=FALSE}
covid <- rio::import("data/covid_LA.csv")
```

```{r echo = FALSE}
covid <- rio::import("data/covid_LA.csv")
```

Now that the dataset is loaded, we can review the data format.

#### **2.2.2. Exploring the Dataset**

In this exercise, to explore the variables contained in the covid object, you can make a general or specific approach to each variable.

For example, you can make a general approach using the str function to identify the type of object, type of variables, and values of the variable. An option within tidyverse is the glimpse function, which allows you to quickly identify the content of the dataset.

⚠️ **Instruction:** Use the `glimpse` or `str` function

```{r eval = FALSE}
covid %>%
  dplyr::glimpse()
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo=FALSE}
covid %>%
  dplyr::glimpse()
```

#### **2.2.3. Applying Best Practices for Naming Variables**

::: callout
**Best Practice Tip:** According to programming best practices, it is recommended that variable names have characteristics such as:

-   Be in lowercase

-   Do not contain special characters

-   Do not contain spaces
:::

These recommendations depend on the preference of the analyst and their team. For this module, we will use the `standardize_column_names` function from the `cleanepi` package.

::: callout
The `standardize_column_names` function has the main argument:

-   `data`: the dataset (or linelist) with the data to be modified.

And two optional arguments:

-   `keep`: a vector with the names of the columns to be kept.

-   `rename`: a vector with the names of the columns to be renamed. E.g.
    `c(new_name1 = “old_name1”, new_name2 = “old_name2”)`
:::

⚠️ **Instruction:** Use the `standardize_column_names` function to clean the names of the covid dataset:

```{r}
covid <- covid %>% 
  cleanepi::standardize_column_names()
```

**Expected result:** The above code does not produce a visible result in the console to observe the change, but by using the glimpse function, we can see the adjusted variable names in the covid dataset.

⚠️ **Instruction:** Use the glimpse function and observe the change in the variable name Tipo de recuperación:

```{r eval=FALSE}
covid %>% 
  dplyr::glimpse()
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo=FALSE}
covid %>% 
  dplyr::glimpse()
```


#### **2.2.4. Summary of Variables**

To start exploring the variables, we will use the summary function.

⚠️️ **Instruction:** Use the summary function to explore the variables:

```{r eval = FALSE}
covid %>%
  base::summary()
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo = FALSE}
covid %>%
  base::summary()
```

::: callout
To know the units of the variables, remember to check the documentation called "covid_LA_info.txt".
:::

In addition to using `summary` as in the previous case, you can also obtain this information for each variable individually. For example, for the `edad` variable, we use `summary` by calling the variable within the dataset.

⚠️️ **Instruction:** Use the summary function to explore the `edad` variable:

```{r eval = FALSE}
covid %>%
  dplyr::select(edad) %>%
  base::summary()
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo = FALSE}
covid %>%
  dplyr::select(edad) %>%
  base::summary()
```

#### **2.2.5. Exploring Quantitative Variables**

Another way to explore quantitative variables is in the form of a graph. Using graphs such as histograms, box plots, trend lines, scatter plots, violin plots, among others. Below are examples for histograms and box plots.

⚠️ **Instruction:** Use the hist function to generate a histogram of the `edad` variable:

```{r eval=FALSE}
covid %>% 
  dplyr::pull(edad) %>% #pull extracts the vector
  graphics::hist()
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo=FALSE}
covid %>% 
  dplyr::pull(edad) %>% #pull extracts the vector
  graphics::hist()
```

⚠️ **Instruction:** Use the boxplot function to generate a boxplot of the `edad` variable:

```{r eval=FALSE}
covid %>% 
  dplyr::pull(edad) %>% 
  graphics::boxplot()
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo=FALSE}
covid %>% 
  dplyr::pull(edad) %>% 
  graphics::boxplot()
```

These graphs can be useful for examining the trend and distribution of the data, as well as observing outliers.

::: callout
To explore more topics on visualization, please refer to the **Unit: Introduction to Data Visualization in R with ggplot2**.
:::

#### **2.2.6. Exploring Qualitative Variables**

Let's delve a little deeper into exploring qualitative variables. When we used `summary` at the beginning of this section, we could see what happened with some qualitative variables. Now let's see what happens with the `nombre_del_pais` variable.

⚠️ **Instruction:** Select the `nombre_del_pais` variable using the select function and use the summary function to see the summary of this variable.

```{r eval=FALSE}
covid %>% 
  dplyr::select(sintomas) %>% 
  base::summary()
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo=FALSE}
covid %>% 
  dplyr::select(sintomas) %>% 
  base::summary()
```

::: discussion
What can you observe?
:::

To obtain details about the categories of the variables, we can use other options such as tables, proportion tables, extracting unique values, and creating graphs. Let's see each one:

⚠️ **Instruction:** Use the table function to generate a table of the `sintomas` variable:

```{r eval=FALSE}
covid %>% 
  dplyr::pull(sintomas) %>% 
  base::table()
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo=FALSE}
covid %>% 
  dplyr::pull(sintomas) %>% 
  base::table()
```

::: discussion
What can you observe?
:::

If we want to see a table with the **percentages** of each element within the variable, we can use the `prop.table` function.

⚠️ **Instruction:** Use the `prop.table` function to generate a table with percentages of the `sintomas` variable:

```{r eval = FALSE}
covid %>%
  dplyr::pull(sintomas) %>%
  base::table() %>%
  base::prop.table()*100 #if you want proportions, you can remove the "*100"
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo = FALSE}
covid %>%
  dplyr::pull(sintomas) %>%
  base::table() %>%
  base::prop.table()*100 #if you want proportions, you can remove the "*100"
```

As you can see, now we can see each category with its respective percentage. If we only want to see the unique values without other data, we can use the `unique` function.

⚠️ **Instruction:** Use the unique function to extract the unique values of the `sintomas` variable:

```{r eval=FALSE}
covid %>%
  dplyr::pull(sintomas) %>%
  base::unique()
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo=FALSE}
covid %>%
  dplyr::pull(sintomas) %>%
  base::unique()
```

With this, we were able to obtain the different values of the `sintomas` variable. Additionally, qualitative variables can be examined using bar or pie charts.

⚠️ **Instruction:** Use the barplot function accompanied by the table function to generate a bar chart of the content of the `sexo` variable:

```{r eval=FALSE}
covid %>%
  dplyr::pull(sintomas) %>%
  base::table() %>%
  graphics::barplot()
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo=FALSE}
covid %>%
  dplyr::pull(sintomas) %>%
  base::table() %>%
  graphics::barplot()
```
 <center>  
   
[![](fig/dudas.png){width="100"}](https://epiverse-trace.github.io/epitkit/Banco_errores.html)  
  
</center>
## **Topic 3: Modification, Cleaning, and Correction of Data: Common Errors and Their Solutions**

### **3.1. Reviewing the Consistency of Variable Content**

To use these conversion functions, we can apply them directly to each variable (e.g., `as.factor(covid$sexo)`) or use the `across` function. The `across` function is a function from the `dplyr` package that allows applying transformations to multiple variables in a data frame simultaneously. 

::: callout
The `across` function has two arguments

1.  `.cols`: the vector of variables to transform.

2.  `.fns`: the function to be applied.
:::

⚠️ **Instruction:** Convert the `sexo`, `sintomas`, and `nombre_del_pais` variables to factor type using the `across` and `as.factor` functions.

```{r}
covid <- covid %>% 
  dplyr::mutate(
    dplyr::across(
    .cols = c("sexo", "sintomas", "nombre_del_pais"), 
    .fns = as.factor))
```

**Expected result:** You can see the result of the above code using visualization functions like summary.

⚠️ **Instruction:** Use the summary function to explore the variables transformed to factor type:

```{r eval=FALSE}
covid %>% 
  dplyr::select(c(sexo, sintomas, nombre_del_pais)) %>%
  base::summary()
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo=FALSE}
covid %>% 
  dplyr::select(c(sexo, sintomas, nombre_del_pais)) %>%
  base::summary()

```

When using the summary function with the variables we just converted to factor type, we can see that the results have changed compared to the first time we used summary in step 4 of topic 2.

::: discussion
What changes can you observe?
:::

To give order to the categories of a factor variable, we can use the `fct_relevel` function.

⚠️ **Instruction:** Use the `fct_relevel` function to modify the order of the categories of the variable:

::: callout
**Hint**: In the first argument, call the variable to be modified, and in the second argument, put a vector with the levels in the desired order.
:::

```{r}
covid <- covid %>%
  dplyr::mutate(sintomas = 
                  forcats::fct_relevel(sintomas,
                                       "Sin sintomas", 
                                       "Leve", "Moderado", 
                                       "Grave", "Critico"))
```

⚠️ **Instruction:** Check if the levels of the variable are in the desired order:

```{r eval=FALSE}
covid %>% 
  dplyr::count(sintomas)
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo=FALSE}
covid %>% 
  dplyr::count(sintomas)
```

Having the levels of the variables in order is essential for proper statistical analysis and correct interpretation of the results.

However, although the documentation specifies that the variable should have a certain data type, for example, for numeric variables, sometimes a dataset may contain numbers written in letters. In this case, when converting to numeric type, the system will not detect them as numeric values and will replace them with `NA` values, resulting in the loss of that information. Let's see an example.

⚠️ **Instructions:**

1.  Using the table function, explore the first 1000 records contained in the `num_hos_rec` variable. What elements can you observe?

```{r eval=FALSE}
covid %>%
  dplyr::slice(1:1000) %>%
  dplyr::pull(num_hos_rec) %>%
  base::table(useNA = "always")
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo=FALSE}
covid %>%
  dplyr::slice(1:1000) %>%
  dplyr::pull(num_hos_rec) %>%
  base::table(useNA = "always")
```

This variable contains numeric elements, characters, and `NA`. To convert the variable to numeric, use the `as.numeric` function.

2.  Before converting the dataset, using the `as.numeric` function, obtain a table of the column in numeric format to explore the consequences of converting it to numeric.

```{r eval=FALSE}
covid %>% 
  dplyr::slice(1:1000) %>%
  dplyr::pull(num_hos_rec) %>%
  base::as.numeric() %>%
  base::table(useNA = "always")
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo=FALSE}
covid %>% 
  dplyr::slice(1:1000) %>%
  dplyr::pull(num_hos_rec) %>%
  base::as.numeric() %>%
  base::table(useNA = "always")
```

::: discussion
What changes could you observe?
:::

When exploring the variable in numeric format, we notice that the numbers remain while the non-numeric elements ("no registra" and "No registra") joined the `NA` group. We will delve into `NA` data later. If you are satisfied with the changes, you can convert the dataset:

```{r}
covid <- covid %>%
  cleanepi::convert_to_numeric(
    target_columns = "num_hos_rec",
    lang = "es")
```

### **3.2. Identifying Erroneous or Missing Values**

In addition to NA values, in our data processing, we may encounter other values such as Inf (infinite values) or NaN (undefined numeric values).

Identifying missing data requires first identifying the cause of the absence of these data.

#### **3.2.1. NA Values**

##### **NAs Related to Incorrect Separators**

Let's see a common example of the appearance of `NA`: when we have different separators for numbers (e.g., in height).

⚠️ **Instruction:** Before converting the dataset, obtain a table (using the table function) that quantifies the NAs resulting from converting the height variable to numeric format with the `as.numeric` function. To check if a value is `NA`, you can use the `is.na` function.

```{r}
covid %>%
  dplyr::pull(talla) %>%
  base::as.numeric() %>%
  base::is.na() %>%
  base::table()
```

Now use the following code to understand why these `NAs` are generated

```{r}
covid %>%
  dplyr::pull(talla) %>%
  utils::head()
```

**Expected result:** As you can see, a warning appears indicating that some values have been converted to `NA`. This is because there are non-numeric elements in the variable. When exploring the content of the variable, we can notice that the height is in a character vector, and the separators include dots, commas, spaces, etc., but in this case, it is a single separator in all cases.

When working with a numeric variable, it is essential to know if its collection and entry were done in a standardized manner and limited to numeric values. To correct errors such as using characters instead of numbers, we can use search and replace functions for characters within the variable's content. One option is to use the `str_replace` function from the `stringr` package in R.

::: callout
The `str_replace` function requires three arguments:

-   `string`: the vector of the variable to be modified.

-   `pattern`: the character to be replaced. However, for convenience, we can use regular expressions. For example, the expression `"[^0-9]"` indicates that any character that is not a number is selected. It is enclosed in quotes.

-   `replacement`: the character that will replace the one in the first argument. It is enclosed in quotes.
:::

⚠️ **Instruction:** Use the `str_replace` function to replace within the height variable (introduced as a character) all elements that are not (\^) numbers from 0 to 9 or a dot: with a dot.

```{r}
covid <- covid %>%
  dplyr::mutate(talla = 
                  stringr::str_replace(
                    string = talla, 
                    pattern= "[^0-9.]",
                    replacement="."))
```

⚠️ **Instruction:** Check if the desired change was made:

```{r}
covid %>%
  dplyr::pull(talla) %>%
  utils::head()
```

⚠️ **Instruction:** Check the effect of the transformation and use the table function to obtain a table that quantifies the NAs resulting from converting the height variable to numeric format with the `as.numeric` function. To check if a value is NA, you can use the `is.na` function.

```{r}
covid %>%
  dplyr::pull(talla) %>%
  base::as.numeric() %>%
  base::is.na() %>%
  base::table()
```

**Expected result:** If the decimal change was successful with the dataset and if replacing it with numeric would not result in NAs. Therefore, it is okay to change it to numeric.

⚠️ **Instruction:** Transform the height variable to numeric format and print the first rows.

```{r}
covid <- covid %>%
  dplyr::mutate(talla = as.numeric (talla))

covid %>%
  dplyr::pull(talla) %>%
  utils::head()
```

As we can see, once the transformation is done, the quotes "" no longer appear, indicating that the conversion to numeric has been made.

##### **NAs Related to Errors in Date Writing**

Sometimes, date writing follows the criteria of the data collector. For example, in a form that contains day/month/year, we may find entries like: "2015-03-15", "15-03-15", "2015-mar-15", "01/mar/2023", "15/15/03", "ene/15". Since correcting numerous dates can be an unfeasible task, the `standardize_dates` function from the `cleanepi` package offers an alternative for automatic correction, as well as converting the column to date format (`date`).

::: callout
The `standardize_dates` function, in addition to the data argument, has a main argument:

-   `target_columns`: the columns that contain the dates to be standardized.

And three optional arguments:

-   `error_tolerance`: the allowed percentage of dates that cannot be corrected before the function stops.

-   `format`: the format of the dates. If left as NULL, the function will try to guess the format. 

-   `timeframe`: the allowed date range. If left as NULL, the function will not restrict the dates. 
:::

⚠️ **Instruction:** Observe how the `fecha_reporte_web` variable is composed.

```{r}
covid %>%
  dplyr::select(fecha_reporte_web) %>%
  dplyr::slice(1:10)
```

As you can see, the dates are presented in various formats, and as seen when we used glimpse, the column is in character format. To standardize these date formats and convert the variable to date format, we will use the `standardize_dates` function. 

⚠️ **Instruction:** Convert the `fecha_reporte_web` variable to date type using the `standardize_dates` function.

```{r}
covid %>%
  dplyr::select(fecha_reporte_web) %>%
  dplyr::slice(1:10) %>%
  cleanepi::standardize_dates() 
```

As you can see, since we did not specify the format, the function identified it automatically. In cases where the identification failed, the data was transformed to `NA`.  Additionally, now the column is in date format (`date`).

⚠️ **Instruction:** Store the change in the `fecha_reporte_web` variable

```{r}
covid <- covid %>%
  cleanepi::standardize_dates(
    target_columns = "fecha_reporte_web")
```

##### **NAs Related to Errors in Number Writing**

In some cases, errors in data collection may not be corrected during data entry, such as writing the name of a number (e.g., "three") instead of the symbol representing the number (e.g., "3").

⚠️ **Instruction:** Using the table function, explore the `num_hos_rec` variable

```{r}
covid %>%
  dplyr::pull(num_hos_rec) %>%
  base::table(useNA = "always")
```

As you can see, there are numbers written as letters and symbols, as well as two categories of data that were not recorded, and there are no `NA`, meaning that all records have some value.

To correct these errors after identifying them, we can replace them one by one with `gsub` or use the `convert_to_numeric` function from the cleanepi package.

::: callout
The `convert_to_numeric` function has 3 arguments:

-   `data`: the dataset (or linelist) with the data to be modified.

-   `target_colum`: the vector that contains the names of the column(s) to be modified.

-   `lang`: The language in which the numbers are written lang = c("en", "fr", "es").
:::

⚠️ **Instruction:** Using the `convert_to_numeric` function, correct the errors in the `num_hos_rec` variable

```{r}
covid <- covid %>%
  cleanepi::convert_to_numeric(
    target_columns = "num_hos_rec",
    lang = "es")
```

⚠️ **Instruction:** Using the table function, check the change in the `num_hos_rec` variable

```{r}
covid %>%
  dplyr::pull(num_hos_rec) %>%
  base::table(useNA = "always")
```

As you can see, the numbers in letters were converted to their respective numeric equivalents. While any element not recognized as a number was converted to `NA`.

##### **NAs Related to Two Data Points in the Same Column**

In some cases, a dataset may contain two variables in the same column.

⚠️ **Instruction:** Explore the first rows of the `tension_arterial` variable.

```{r}
covid %>%
  dplyr::pull(tension_arterial) %>%
  utils::head()
```

**Expected result:** Consistent with what is mentioned in the dataset documentation "covid_LA_info.txt", the `tension_arterial` variable contains two data points in the same column (systolic blood pressure and diastolic blood pressure separated by "/").

To solve this problem, we can use the `separate_wider_delim` function from the `tidyr` library within the `tidyverse` package.

::: callout
The `separate_wider_delim` function, in addition to data, has three main arguments.

-   `cols`: requires the vector that contains the column of a data frame.

-   `delim`: requires the separator used to separate the data.

-   `names`: requires the names of the columns to be created.
:::

⚠️ **Instruction:** Using the `separate_wider_delim` function, separate the `tension_arterial` variable into two variables: `tension_sistolica` and `tension_diastolica`.

```{r}
covid <- covid %>%
  tidyr::separate_wider_delim(cols = tension_arterial,
                              delim = "/",
                              names = c("tension_sistolica",
                                        "tension_diastolica"))

covid %>%
  dplyr::pull(tension_sistolica) %>%
  utils::head()
```

```{r}
covid %>%
  dplyr::pull(tension_diastolica) %>%
  utils::head()
```

**Expected result:** The above code generates the changes directly in the `covid` dataset, and the two new columns are obtained.

It is important to remember that all these changes depend on the variables being worked on, and the data analyst must use their judgment in each circumstance and perform tests to ensure that the results are as expected.

#### **3.2.2. Infinite Values (`Inf`)**

Infinite values can be generated when an operation results in a number too large (Inf+) or too small (Inf-) for R. In R, if we try to calculate values greater than or equal to 2\^1024 (larger than the number of grains of sand on Earth) or when dividing a number by values very close to 0, specifically less than 1/1e-309, we will get Inf. In the case of values less than 1e-324, R assumes them as 0:

⚠️ **Instruction:** Observe the results of the following operations:

```{r}
2^1024
```

```{r}
-2^1024
```

```{r}
1/1e-309
```

```{r}
1/0
```

The appearance of `Inf` values can happen at any time during data handling, particularly when there is a mistake in performing arithmetic operations. For example, when trying to calculate the number of days lived, and instead of using the multiplication operator (\*), the power operator (\^) was used.

```{r}
covid <- covid %>%
  dplyr::mutate(edad_en_dias = edad * 365)

covid %>%
  dplyr::pull(edad_en_dias) %>% 
  utils::head()
```

#### **3.2.3. Undefined Values (`NaN`)**

These values are generated when performing mathematically undefined operations. For example, if we try to divide zero by zero or subtract or divide an infinite number by another infinite number, we will get `NaN` (which means "Not a Number"). Below are some examples:

⚠️ **Instruction:** Observe the following operations

```{r}
Inf/Inf
```

```{r}
Inf-Inf
```

```{r}
0/0
```

Although results like `Inf` or `NaN` may seem impossible, they can appear when we make a mistake in converting variables or creating a variable after an erroneous operation, and the error propagates in subsequent operations.

#### **3.2.4. Duplicate Data**

Another common error is duplicate data. These can be either a duplicate observation of a variable or an entire duplicate record.

⚠️ **Instruction:** Explore if values are repeated in the `id_de_caso` variable

```{r}
covid %>%
  dplyr::pull(id_de_caso) %>%
  base::table() %>%
  base::table()
```

As you can see, at least 1000 identification codes are repeated in the dataset two or three times. But at this point, we still don't know if these 1000 records are errors or simply correspond to two different records of the same person (e.g., reinfections).

To identify which records (rows) are entirely duplicated in all their variables and are indeed errors, we can use the duplicated function and sum the records like this:

```{r}
covid %>%
  base::duplicated() %>%
  base::sum()
```

To solve this problem, we can use the `remove_duplicates` function from cleanepi, which allows removing rows that are exactly duplicated.

::: callout
The `remove_duplicates` function has the main argument:

-   `data`: the dataset (or linelist) with the data to be modified.

And an optional argument:

-   `target_columns`: a vector with the names of the columns to be used to search for duplicates.
:::

⚠️ **Instruction:** Using the `remove_duplicates` function, remove the duplicated rows from the covid dataset.

```{r}
covid <- covid %>%
  cleanepi::remove_duplicates()
```

As you can see in the output, the function detected 2391 entirely duplicated rows (they may be present two or more times). If you explore the `covid` dataset again, you will see that 1196 rows have disappeared. Additionally, you will see that a new column called `row_id` has been generated in the dataset.

Now let's see the effect on unique identifiers.

```{r}
covid %>%
  dplyr::select(id_de_caso) %>%
  base::table() %>%
  base::table()
```

According to this table, once we removed the duplicated records, there are 1005 case identifiers (`id_de_caso`) that are recorded twice.

If you want to keep only the first record of each case, you can use the same `remove_duplicates` function with the additional `target_columns` argument to specify the columns. Let's see an example.

️**Instruction:** Using the `remove_duplicates` function, remove the duplicated `id_de_caso` data from the dataset.

```{r}
covid <- covid %>%
  cleanepi::remove_duplicates(
    target_columns = "id_de_caso")
```

As you can see, 2010 duplicated `id_de_caso` were found. Therefore, if you explore the `covid` dataset, you will see that the effect is the removal of 1005 rows. Note that the user must be sure to remove these rows; otherwise, they can run the function without overwriting the object to observe the results and store it when sure.

#### **3.2.5. Typographical Errors**

Sometimes, we may find that the categories of a variable have been written in multiple ways. Let's see an example:

```{r}
covid %>%
  dplyr::pull(ubicacion_del_caso) %>%
  base::table(useNA = "always")
```

To correct this error, we can use the `gsub` function to replace the incorrect value "casa" with the value we have selected as correct, "Casa".

```{r}
covid <- covid %>%
  dplyr::mutate(ubicacion_del_caso = 
                                   base::gsub(pattern= "casa",
                                        replacement="Casa",
                                        x= ubicacion_del_caso))
```

As a result, the values have been replaced:

```{r}
covid %>%
  dplyr::pull(ubicacion_del_caso) %>%
  base::table(useNA = "always")
```

 <center>  
   
[![](fig/dudas.png){width="100"}](https://epiverse-trace.github.io/epitkit/Banco_errores.html)  
  
</center>

#### **3.2.6. Replacing Missing Values**

In some cases, datasets contain values that do not correspond to the categories of the variables, are missing, or from the documentation, we know that these values correspond to `NA`. To ensure robust analysis, it is a good practice to replace all these values with `NA`. To do this replacement, we can use the `replace_missing_values` function from the cleanepi package.

::: callout
The `replace_missing_values` function, in addition to data, has optional arguments:

-   `na_strings`: the vector with the characters that represent the missing values (e.g., "missing", "NA", "N A"). If this argument is not provided, the predefined values in the vector cleanepi::common_na_strings will be used.

-   `target_columns`: a vector with the names of the columns in which the function will be executed.
:::

⚠️ **Instruction:** Review the content of the `ubicacion_del_caso` variable:

```{r}
covid %>% 
  dplyr::pull(ubicacion_del_caso) %>% 
  base::table(useNA = "always")
```

⚠️ **Instruction**: Review the documentation for possible NAs that may appear in the dataset and replace them with NA.

```{r}
covid <- covid %>%
  cleanepi::replace_missing_values( na_strings = "N/A")
```

**Instruction:** Review the content of the `ubicacion_del_caso` variable to see the changes:

```{r}
covid %>%
  dplyr::pull(ubicacion_del_caso) %>%
  base::table(useNA = "always")
```

#### **3.2.7. Columns with Constant Values**

In some cases, it is possible to find columns that contain only one value. This can happen, for example, when a larger dataset is divided into a smaller fraction. In these cases, the column that was used to separate the data becomes unnecessary. For these cases, we can use the `remove_constants` function from the cleanepi package.

::: callout
The `remove_constants` function has the main argument:

-   `data`: the dataset (or linelist) with the data to be modified.
:::

⚠️ **Instruction:** Using the `remove_constants` function, remove the rows with constant values. 

```{r}
covid <- covid %>%
  cleanepi::remove_constants()
```

To verify the number of columns remaining after the process, you can use the `ncol` function:

```{r}
covid %>%
  base::ncol()
```

#### **3.2.8. Verification of Outliers**

To evaluate if the data is within an expected range or if there are outliers, we can use the creation of graphs or explore the head and tail of the data when sorted; for example, in the case of dates, we can create historical curves, or if they are ages, using histograms or box plots.

Identifying outliers can vary depending on the data analyst's criteria and the characteristics of the variable. For example, in the age variable, while values above 100 years are rare, they are biologically viable; however, an age of 200 years could be considered an outlier. In the case of date variables, outliers can arise when there are dates that do not follow the expected behavior. Let's see an example with dates:

⚠️ **Instruction:** Before starting, make sure the variable is in date format. To check, you can use the **`class`()** function.

```{r}
covid %>%
  dplyr::pull(fecha_reporte_web) %>%
  base::class()
```

If your variable is not in date format (`date`), please review the section **NAs Related to Errors in Date Writing** and use the function learned there.

⚠️ **Instruction:** Using the `hist` function, create a histogram of the dates when cases were reported by week.

```{r eval = FALSE}
covid %>%
  dplyr::pull(fecha_reporte_web) %>%
  graphics::hist(breaks = "weeks")
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo = FALSE}
covid %>%
  dplyr::pull(fecha_reporte_web) %>%
  graphics::hist(breaks = "weeks")
```

As we can see, the graph starts from 1969. For epidemiological reasons, we quickly analyze that since these are COVID cases, we would expect the records to start from 2020. This indicates that there may be a date that is incorrectly entered, resulting in the above histogram.

In this case, we can sort the data using the arrange function from the dplyr package within tidyverse to see the ordered dates and identify potential erroneous dates at the beginning of the series. As shown in the example below:

⚠️ **Instruction:** Observe the data at the beginning of the dataset when sorted by date.

```{r eval=FALSE}
covid %>%
  dplyr::arrange(fecha_reporte_web) %>%
  dplyr::select(fecha_reporte_web) %>%
  utils::head()
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r}
covid %>%
  dplyr::arrange(fecha_reporte_web) %>%
  dplyr::select(fecha_reporte_web) %>%
  utils::head()
```

In the first row, we have the value outside the expected range, that is, a date of 1970. In this case, it is a single data point that we need to correct, but there could be several hundreds of these. To correct this type of error, we can remove the rows containing these data or reassign these values to NA to avoid losing other information.

#### **3.2.9. Correcting Errors in Dates**

Once the data has been explored and potential errors identified, we can explore the corrective measures to be used. In this case, considering that the first COVID cases in Latin America were in February 2020, we will use February 1, 2020 (2020-02-01) as the date from which we will consider these data as valid. We can define the cutoff date based on the epidemiological context or documentation.

⚠️ **Instruction:** Filter the data by the report date before the date "2020-02-01".

```{r eval=FALSE}
covid %>%
  dplyr::filter(fecha_reporte_web < as.Date("2020-02-01"))
```

**Expected result:** Using the above code with the same dataset, you get the following result:

```{r echo=FALSE}
covid %>%
  dplyr::filter(fecha_reporte_web < as.Date("2020-02-01"))
```

Once the data is identified, we can correct it by replacing it with the correct value (if known), converting it to NA, or excluding it from the analysis.

⚠️ **Instruction:** Using the filter function, exclude the dates before "2020-02-01" in the `fecha_reporte_web` variable. Remember to use the expression ! before the variable name to achieve an inverse selection.

```{r}
covid <- covid %>% 
  dplyr::filter(!fecha_reporte_web < as.Date("2020-02-01"))
```

Now let's reproduce the graph and observe.

⚠️ **Instruction:** Reproduce the histogram with the correction in the dates.

```{r}
covid %>%
  dplyr::pull(fecha_reporte_web) %>%
  graphics::hist(breaks = "weeks")
```

**Expected result:** Using the above code with the same dataset, you get the following result:

#### **3.2.10. Filtering Records with NA**

In certain analyses, it may be necessary to exclude NA values. To achieve this, we can use the filtering function provided by `dplyr`. This allows us to focus on complete data.

⚠️ **Instruction:** Review the content of the `ubicacion_del_caso` variable:

```{r}
covid %>%
  dplyr::pull(ubicacion_del_caso) %>%
  base::table(useNA = "always")
```

**Instruction**: Filter the `ubicacion_del_caso` variable to exclude records with `NA` present in this variable:

```{r}
covid <- covid %>%
  dplyr::filter(!is.na(ubicacion_del_caso))
```

**Instruction:** Review the content of the `ubicacion_del_caso` variable to see the changes:

```{r}
covid %>% 
  dplyr::pull(ubicacion_del_caso) %>% 
  base::table(useNA = "always")
```

As you can see, now the NAs are 0.

#### **3.2.11. Replacing Acronyms, Abbreviations, or Coded Values**

In the process of data collection or entry, it is common to use acronyms, abbreviations, or codes to record information. For example, in the case of the gender variable, sometimes "1", "m", or "M" may be used to represent male gender, and "2", "f", or "F" for female gender, among other options. If we have a dictionary for converting these values, we can use the `clean_using_dictionary` function from the `cleanepi` package to perform the replacement.

Since we don't have a dictionary at the moment, we can create one.

```{r}
diccionario <- base::data.frame(
  options = c("1", "2", "M", "F", "m", "f"),
  values = c("masculino", "femenino", "masculino",
             "femenino", "masculino", "femenino"),
  grp = rep("sexo", 6),
  orders = 1:6)
```

⚠️ **Instruction:** Review the content of the `sexo` variable:

```{r}
covid %>%
  dplyr::pull(sexo) %>%
  base::table(useNA = "always")
```

::: callout
The `clean_using_dictionary` function has the main argument:

-   `data`: the dataset (or linelist) with the data to be modified.

-   `dictionary`: a dictionary that contains the values to be replaced in the current data. Each key in the dictionary represents an original value in the dataset, and the value associated with that key is the new meaning to be assigned to the data.
:::

⚠️ **Instruction:** Apply the `clean_using_dictionary` function to the dataset:

```{r}
covid <- cleanepi::clean_using_dictionary(covid,
                                          dictionary = diccionario)
```

⚠️ **Instruction:** Review the content of the `sexo` variable to see the changes:

```{r}
covid %>%
  dplyr::pull(sexo) %>%
  base::table(useNA = "always")
```


 <center>  
   
[![](fig/dudas.png){width="100"}](https://epiverse-trace.github.io/epitkit/Banco_errores.html)  
  
</center>


## **Topic 4: Data Organization**

Finally, we can perform some data organization activities. For example:

### 4.1. Removing Duplicate or Unnecessary Variables

During data exploration, it is possible to find variables whose content is not necessary for the analysis or that are no longer needed. To optimize memory usage on the computer, we can remove these variables. To achieve this, we can use the select function from the tidyverse package.

⚠️ **Instruction:** Using the select function accompanied by the - symbol, remove the `edad_repetida` variable.

```{r}
covid <- covid %>%
  dplyr::select (!edad_repetida)
```

### 4.2. Organizing Variables

Part of organizing variables includes assigning appropriate names to the variables according to the project's needs. This can be achieved using the `rename` function from `dplyr`.

⚠️ **Instruction:** Using the rename function, change the name of the `fecha_de_inicio_de_sintomas` variable to a shorter name, such as `inicio_sintomas`.

```{r}
covid <- covid %>%
  dplyr::rename(inicio_sintomas = fecha_de_inicio_de_sintomas)
```

What other columns would you rename?

### 4.3. Storing the Clean Dataset

Once the modification, cleaning, and correction of the data are completed, we can save the clean dataset. This is because all the changes made have been saved only in the R session and will be lost once it is closed. To do this, we can use the export function from the rio package.

::: callout
The `export` function requires at least two arguments:

1.  x: The **name of the object** to be saved in the file.

2.  file: The **name of the file** with its extension (e.g., datos_limpios_covid.RDS). If it will be stored in a folder, add the path to the folder before the file name (e.g., data/clean/datos_limpios_covid.RDS).
:::

⚠️ **Instruction:** Create a directory for clean data and save the corrected data in your preferred format. We recommend .RDS.

```{r eval=FALSE}
rio::export(covid, "data/clean/datos_limpios_covid.RDS")# save the data
```

**Expected result:** To see the result, go to your data folder and the clean subfolder. There you will see a file called datos_limpios_covid.RDS. You can also save the file in .xls or .xlsx format for Excel, as well as in many other formats. However, RDS is recommended for its low weight and storage capacity.

 <center>  
   
[![](fig/dudas.png){width="100"}](https://epiverse-trace.github.io/epitkit/Banco_errores.html)  
  
</center>

::: keypoints

Check if at the end of this lesson you have acquired these skills:

-   Recognize the tools that facilitate the cleaning of epidemiological data.

-   Identify good practices for cleaning epidemiological data.

-   Explore the process of cleaning, organizing, and characterizing epidemiological data.

:::

### Contributions

-   Zulma M. Cucunuba: Initial version
-   Laura Gómez-Bermeo: Editing
-   Geraldine Gomez: Minor edits
-   Andree Valle: Minor edits
-   José M. Velasco España: Minor edits

### Legal Issues

**Copyright**: Zulma M. Cucunuba, 2019

---
title: "Statistics and Probability Unit"
authors: ["Erika Cantor, Zulma Cucunuba"]
date: '2024-09-31'
output:
  pdf_document: default
  html_document: 
    self_contained: true
  word_document: default
image: null
licenses: CC-BY
teaching: 40
exercises: 4
editor_options: 
  markdown: 
    wrap: 72
---

::: questions

-   How can statistics and probability be used to answer questions in the epidemiology of infectious diseases?
:::

::: objectives

**At the end of this workshop you will be able to:**

-   Understand the role of statistics in the study of infectious diseases.

-   Understand statistical measures to summarize and analyze information.

-   Familiarize yourself with the concept of a random variable and recognize the main probability distributions.

-   Identify and understand the process of the statistical problem as an inference problem from a sample.

-   Understand the concept of confidence interval and the procedure of hypothesis testing.
:::

::: prereq
This unit has the following prerequisites:

-   Introduction to R and RStudio
-   Visualization with ggplot2

This unit is a complement to the ***Course in Data Science in Public Health and Infectious Disease Modeling***
:::


::: callout

### **Table of Contents**

+-----------------------------------------------------------------------+
| -   Topic 1: Introduction to Statistical Thinking (See on course      |
|     platform)                                                         |
|                                                                       |
| -   Topic 2: Descriptive Statistics (See supplement on course         |
|     platform)                                                         |
|                                                                       |
| -   Topic 3: Probability (See supplement on course platform)          |
|                                                                       |
| -   Topic 4: Main Probability Distributions (See supplement on course |
|     platform)                                                         |
|                                                                       |
| -   Topic 5: Introduction to Statistical Inference (See supplement on |
|     course platform)                                                  |
+-----------------------------------------------------------------------+
:::

## Before you start

Please check that you have the `tidyverse, pak, epiparameter, and infer` libraries installed. If they are not installed, run the following code as needed:

```{r,eval=FALSE}
# To install the epiparameter package if you don't have it (or are not sure if you have it), run the following code

if(!require("pak")) install.packages("pak")
if(!require("epiparameter")) pak::pak("epiverse-trace/epiparameter")

# To install the tidyverse package if you don't have it (or are not sure if you have it), run the following code

if(!require("tidyverse")) install.packages("tidyverse")


# To install the infer package if you don't have it (or are not sure if you have it), run the following code

if(!require("infer")) install.packages("infer")

# To install the epitools package if you don't have it (or are not sure if you have it), run the following code

if (!require(epitools)) install.packages("epitools")

# To install the cfr package if you don't have it (or are not sure if you have it), run the following code

if (!require("cfr")) install.packages("cfr")

```
 
 <center>  
   
[![](fig/dudas.png){width="100"}](https://epiverse-trace.github.io/epitkit/Banco_errores.html)  
  
</center>  
   
## **Topic 2: Descriptive Statistics**

**Exercise: Visualizing and Analyzing Data in R**

There are many graphs depending on the type of scale of the variable to be analyzed. Below we will present some examples to understand these concepts.

-   Make sure to complete the unit on Introduction to R and the unit on Data Visualization. The data table for this exercise can be found at:
    <https://github.com/TRACE-LAC/TRACE-LAC-data/raw/main/otros/muestra_covid.RDS> 

-   Once you have downloaded the data to your computer and placed it in the data folder of your project, you can run the following command:

```{r}
muestra_covid <- 
  base::readRDS("data/muestra_covid.RDS")
```

**Histogram and Boxplot**

The two most common types of graphs for visualizing the distribution of quantitative variables are histograms and boxplots.

**Histograms** allow you to visually describe the distribution of data by grouping the data into intervals on the x-axis, which are usually of equal size, and then describing the absolute frequency, relative frequency, or density on the y-axis for each interval. A density histogram adjusts the relative frequency of each interval according to its width. In R, it can be constructed as follows:

```{r}
library(ggplot2)
library(dplyr)

# Histogram with absolute frequency

ggplot(muestra_covid, aes(x = edad)) +
  geom_histogram(color = "darkblue", 
                 fill = "lightblue") +
  labs(y = "Absolute Frequency", x = "Age in years",
       title = "Age Distribution")
```

```{r}
# Histogram with density

ggplot(muestra_covid, aes(x = edad)) +
  geom_histogram(aes(y = after_stat(density)),
                 color = "darkblue",
                 fill = "lightblue") +
  labs(y = "Density", x = "Age in years",
       title = "Age Distribution")
```

**Boxplots** are constructed by visualizing the following statistics horizontally or vertically:

-   First quartile Q1 (25th percentile): Value that leaves 25% of the data below it. "First Line"

-   Second quartile Q2 (50th percentile or median): Value that leaves 50% of the data below it. "Middle Line"

-   Third quartile Q3 (75th percentile): Value that leaves 75% of the data below it. "Third Line"

    ![](fig/boxplot.png)

Additionally, these graphs are useful for detecting outliers by establishing a lower limit (Q1-1.5×IQR) and an upper limit (Q3+1.5×IQR) based on the IQR=Q3-Q1. Data outside these limits are considered unusual and should be reviewed. In the presence of outliers, the lines or whiskers extend to the lower or upper limits; otherwise, they extend to the minimum and maximum values, respectively.

Another use of **boxplots** and **histograms** is to understand the shape of the distribution to decide the best measure of central tendency. Thus, a distribution can be symmetric or positively/negatively skewed. When there is symmetry, it is recommended to use the mean accompanied by the standard deviation, and otherwise, the median and interquartile range, as the mean can be influenced by extreme values in the distribution. Remember that a measure of central tendency should always be accompanied by its respective measure of variability.

![](fig/distribucion.png)

-   **Explanatory Legend A:** In a symmetric distribution, the mean, mode, and median take the same value, and the data are evenly distributed around the central value. For this type of distribution, it is recommended to describe the data series with the mean and standard deviation.

-   **Explanatory Legend B:** Positively skewed distribution. This type of distribution is characterized by having a higher concentration of data towards the minimum of the distribution, but some values are concentrated towards the maximum. The expected behavior is that the mean>median>mode, as the mean is influenced by the extreme positive values of the distribution. It is recommended to describe the data using the median and interquartile range.

-   **Explanatory Legend C:** Negatively skewed distribution. This type of distribution is characterized by having a higher concentration of data towards the maximum of the distribution, but some values are concentrated towards the minimum (left side). The expected behavior is that the mode>median>mean, as the mean is influenced by the extreme values on the left side. It is recommended to describe the data using the median and interquartile range.

Next, we will visualize the age of COVID-19 cases using a boxplot.

```{r}
# Boxplot

ggplot(muestra_covid, aes(x = "", y = edad)) +
  geom_boxplot(outlier.shape = NA)
```

According to the boxplot of the age of the COVID-19 sample cases, it can be concluded that the data distribution is positively skewed, as there is a closer proximity between the values of Q1 and the median. Therefore, it is recommended to describe the behavior using the median and interquartile range, which can be found in R as follows using the highlighted functions:

```{r}
# Descriptive Statistics for Quantitative Variables

muestra_covid %>%
  dplyr::summarise(
  n = n (), # Number of observations
  mean = mean(edad), #Mean
  sd = sd(edad), #Standard deviation
  median = quantile(edad, 0.50), # Median-50th Percentile
  P25 = quantile(edad, 0.25), # 25th Percentile
  P75 = quantile(edad, 0.75)) # 75th Percentile
```

Finally, for the age variable, it can be concluded that half of the COVID-19 patients are between 27 and 52 years old ("IQR") with a median of 38 years, indicating that half of the cases are below this age. It is important to note that due to the skewness of the distribution, the mean and median do not coincide, which is expected in skewed distributions.

 <center>  
   
[![](fig/dudas.png){width="100"}](https://epiverse-trace.github.io/epitkit/Banco_errores.html)  
  
</center>
 
**Bar Chart and Frequency Tables**

Qualitative variables are recommended to be represented using bar charts. Generally, these are constructed by indicating the categories of the variables on the X-axis and the values of the absolute frequencies, relative frequencies, or percentages on the Y-axis, depending on the needs. This means that it is always necessary to first evaluate the frequency table of the variable. Suppose we want to know the type of COVID-19 contagion. This can be done in R using the following command:

```{r}
tabla <- muestra_covid %>% # create the frequency table
  dplyr::count(tipo_de_contagio) %>% #count frequency for the variable estado
  dplyr::mutate(prop = base::prop.table(n), #proportion
                perc = base::prop.table(n)*100) #percentage

tabla
```

With this information, it can be concluded that 70% of COVID-19 cases were community-acquired, and only 0.06% were imported from other places. This can be visualized using a bar chart:

```{r}
ggplot(data = tabla, aes(x = tipo_de_contagio, y = perc)) +
  geom_bar(stat = "identity", color = "darkblue", fill = "lightblue")+
  labs(y = "%", x = " ",title = "Type of Contagion")
```
   
<center>  
   
[![](fig/dudas.png){width="100"}](https://epiverse-trace.github.io/epitkit/Banco_errores.html)  
  
</center>
  
## **Topic 3: Probability**

In a study published in the NEJM in 2014 titled "Ebola Virus Disease in West Africa- The First 9 Months of the Epidemic and Forward Projections" ([**DOI:
10.1056/NEJMoa1411100**](https://www.nejm.org/doi/full/10.1056/NEJMoa1411100)), the clinical and epidemiological characteristics of Ebola cases reported during the epidemic that affected Guinea, Liberia, Nigeria, and Sierra Leone since December 2013 were described. In that study, it was found that individuals over 44 years old had a higher probability of dying from the disease. Similarly, to the reference article, a comparable conclusion can be reached by performing an equivalent calculation using association measures seen in the General Epidemiology Unit applied to infectious diseases, such as Relative Risks (RR) or Risk Ratios (RR). To do this, a 2x2 table can be reconstructed, where the RR can be measured by the ratio between the CFR of group A (e.g., cases aged 45 or older) and group B (e.g., cases aged 44 or younger), where the CFR is the case fatality risk.

Thus, it is found that the risk of death in cases aged 45 or older is 1.20 times the risk of death in cases aged 44 or younger, with a 95% confidence interval of 1.13 to 1.27, and a p-value less than 0.01. To reproduce this calculation, you can use the **epitools** library as shown below.

```{r}
library(epitools)

tabla2x2 <- matrix(c(311, 51, 768, 299),nrow = 2, ncol = 2)

epitools::riskratio(tabla2x2)
```

In Topic 5 of this Unit, you will find an introduction to statistical inference and confidence intervals.

 
 <center>  
   
[![](fig/dudas.png){width="100"}](https://epiverse-trace.github.io/epitkit/Banco_errores.html)  
  
</center>  
   
## **Topic 4: Main Probability Distributions**

As described in Topic 3, probability studies the behavior of random phenomena "events". In this process, **random variables (r.v.)**, usually denoted as **X**, aim to assign a real number to each event that can occur in the sample space.

For the explanation and examples of the main distributions, it is important to install and load the **epiparameter** package from Epiverse.

```{r}
#load the epiparameter library
library(epiparameter)
```

**Discrete Models**

The binomial distribution describes the probability of occurrence of an event with two possible outcomes, success (p) or failure (1-p), in a fixed number of independent trials n with a constant probability of success p. The random variable under study is:

X: Number of successes in n trials

The binomial model can be useful to know the probability of observing a certain number of events (e.g., cases, deaths, reinfections) in a population of size n under the assumption that the probability of the event is constant. The binomial distribution depends on two parameters: the probability of success p and the number of independent trials n.

If X has a binomial distribution, it is represented as follows. X\~Bin(n,p)

And its density function, mean, expectation, and variance are:

$f(x)=P(X=x)=(n x )$

$p^x (1-p)^{(n-x)}$

$E(x)=np$\
$Var(x)=np(1-p)$

Example: If in a community of 20 individuals a virus with an attack rate of 60% is introduced, what is the probability that 10 or fewer individuals will be infected?

Let $X~Bin(n=20,p=0.60)$, then we need to calculate the following expression:

$P(X≤10)=∑_(x=0)^10 (20 x ) 〖0.60〗^x (1-0.60)^(20-x)$

In R, this can be calculated as follows:

```{r}
p <- 0.60 
n <- 20 
x <- 10 

pbinom(x,n,p, lower.tail = TRUE)
```

Therefore, the probability that at most 10 individuals will be infected is 24.5%.

In [distribution-zoo](https://ben18785.shinyapps.io/distribution-zoo/)
you can visualize the complete distribution of the variable

$X~Bin(n=20,p=0.60)$. Thus, it can be concluded that on average, 12 infections are expected in a community of 20 individuals with an attack rate of 60%.

![](fig/distribution-zoo.png)

**Poisson Distribution**

The *Poisson* distribution models the behavior of random variables that describe the number of events, "counts," that occur in a fixed observation interval, such as time (number of infections occurring in an hour, day, week, year, etc.) or area (number of infections occurring in a municipality, hospital, etc.).

This distribution has a parameter called lambda ($λ$), $λ>0$, which describes the average number of events that occur in the fixed observation interval. If $X$ has a Poisson distribution, it is represented as follows:

$X$\~$Poisson(λ)$

Its density function, expectation, mean, and variance are:

$fx=P(X=x)=\frac{e^{-λ}λ^x}{x!}, x=0,1,2,..,$

$E(x)=λ Var(x)=λ$

In infectious diseases, the Poisson distribution can be used to model the number of secondary cases generated by a primary case. In this context, the parameter is a function of the effective reproduction number **R**, which represents the average number of secondary infections caused by each primary case over time in a population composed of susceptible and non-susceptible individuals.

::: challenge
[**Example**]{.underline}

Suppose we want to study the spread of an outbreak based on a Poisson model over time (t). The random variable of interest is:

$X_{(t )}$: Number of secondary cases caused by each primary case on day t

This is a Poisson model because there is a fixed observation interval "each primary case," and we want to study the number of secondary cases observed "events." Thus, we could construct the following model:

$X_{(t )}∼Poisson (λ= R X_{(t-1)})$

The above expresses that the average number of secondary cases on day t depends on the reproduction number $R$ and the number of cases observed $X$ the previous day $(t-1)$. However, R is difficult to know in real life, and it may be of interest to approximate its value based on the observed data during the outbreak to generate control strategies.

Suppose that on day 1 of the outbreak $(t=1)$, a total of 5 new cases were reported, and on the next day $(t=2)$, 10 new cases were reported. With this information, we are interested in studying the number of secondary cases on day 2, which is equivalent to:

$X_{(2 )}$: Number of secondary cases caused by each primary case on day 2

This has the following distribution:

$X_{(2 )}∼Poisson (λ= R *5)$

From here, we could estimate the value of $R$ by discovering which value maximizes the probability of observing this specific number of secondary cases on day 2, that is:

$P(X_{(2 )}=10)=\frac{e^{-(R *5)} (R *5)^{10}}{10!}$

**In R, we could discover this by varying different values of the reproduction number (R) as follows:**

```{r}
# Calculate Poisson probability
prob_poisson <- function(x1, x2, r){
  dpois(x2, r*x1)
}

 # Apply the function with the observed data

reproduction_numbers <- base::seq(0,5,0.01) # Different values of R
poisson_results <- base::vector(length = base::length(reproduction_numbers))

#create an empty vector 

for (i in seq_along(reproduction_numbers)){
 poisson_results[i] <- prob_poisson(x1 = 5, x2 = 10, r = reproduction_numbers[i])
}

results_data <- base::data.frame(reproduction_numbers, poisson_results)
most_probable_number <- results_data %>%  dplyr::filter(poisson_results == max(poisson_results)) %>%  dplyr::pull(reproduction_numbers) 

p <- ggplot(data = results_data, aes(x = reproduction_numbers, y = poisson_results)) + geom_line() +  geom_vline(xintercept = most_probable_number ,color = "red", size=1)

p+labs(y = "Probability", x = "Reproduction Number (R) ",title = "Poisson Model")
```

Therefore, if the number of secondary cases follows a Poisson distribution, there is a high probability that the number of new cases observed on day 2 was generated with a reproduction number of R=2. This implies that the average number of secondary cases per primary case is 2. However, this simple model assumes that the number of secondary cases generated by each primary case has the same mean and variance, which implies that all primary cases generate a similar average number of secondary cases. This assumption may be difficult to make in some infectious diseases, especially when they follow a pattern of overdispersion (20% of cases cause 80% of transmission), so the Poisson model has limitations in its application.
:::

**Negative Binomial Distribution**

Like the Poisson distribution, the negative binomial distribution allows modeling the number of events that occur "counts." If $X$ has a Negative Binomial distribution, it is represented as follows.

\$X $~$ NB(μ,k)\$

Where, $μ$ represents the mean of the distribution, and $k$ is the dispersion parameter that allows the mean and variance of the events to be different. This parameter $k$ allows introducing the degree of variation in how the events are generated into the model. Thus, $k$ inversely measures the degree of variation of the events that occurred, as the mean and variance of the distribution are:

$E(x)=μ$

$Var(x)=μ(1+\frac{μ}{k})$

With the density function:

$f(x)=\frac{Γ(x+k)}{Γ(k)Γ(x+1)} (\frac{μ}{μ+k})^x (\frac{k}{μ+k})^k,x=0,1,2...$

::: challenge
[**Example**]{.underline}

In the study of infectious diseases, the negative binomial distribution plays a relevant role as it allows modeling the distribution of the number of secondary cases generated by a primary case, that is, it allows understanding the distribution of the basic reproduction number $R_0$. In this context, the mean of the distribution corresponds to $R_0$ (Number of secondary cases in a fully susceptible population), and the parameter $k$ controls the variation among primary cases. Thus, small values of k suggest that secondary cases are generated by a small group of primary cases, while large values suggest that the spread of the virus is high. Thus, being $X$ the number of secondary cases, then:

$X \sim NB(R_0,k)$

$E(x)=R_0$

$Var(x)=R_0 (\frac{1+R_0}{k})$

In the article by Lloyd-Smith et al., it is shown how the negative binomial distribution allows modeling the distribution of secondary cases of various pathogens. Based on the cases reported during the SARS outbreak in Singapore in 2023, the parameters of the negative binomial distribution were estimated, finding $R_0=1.630$ and $k=0.160$. These estimates are available in the `epiparameter` package, which is an available package in `R` that compiles the main estimates for various epidemiological parameters of interest in the study of infectious diseases.

```{r}
SARS_R <- epiparameter::epiparameter_db(
    disease = "SARS",
    epi_name = "offspring distribution",
    single_epiparameter = TRUE
)
SARS_R
```

With these results, it would be possible to graph the distribution of secondary cases of SARS to suggest control measures. This is also available in the `epiparameter` package with the `plot` function.

```{r}
plot(SARS_R)
```

Finally, it can be concluded that most SARS-infected cases do not spread the disease, as the mode of the distribution is $0$. This result is expected since $k<1$, indicating that secondary cases are generated by a small group of infected individuals, and the estimated value of $R_0$ varies for the cases.
:::

**Geometric Distribution**

Another discrete distribution of interest that can be used to model counts or the number of events is the geometric distribution. In infectious diseases, its main use arises when the dispersion parameter of the negative binomial distribution is equal to 1. This distribution depends on the probability of the event of interest occurring and is represented as follows.

$X \sim Geom(p)$

where p represents the probability of success or the probability of the event of interest occurring, with a mean equal to:

$E(x)=\frac{1}{p}$

::: challenge
**Example**

If in the case of the SARS outbreak in Singapore in 2023, the estimated value of $k$ had been $1$, then the distribution of secondary cases could be modeled with a geometric distribution such that its mean is equal to the estimated $R_0$, that is, it must be satisfied that:

$E(x)=\frac{1}{p}=1.630$ and therefore, $p=\frac{1}{1.630}$

Thus, the distribution of the number of secondary contacts could be written as:

$X \sim Geom(p=0.613)$

In R, we could simulate the behavior of the number of secondary cases with the following code:

```{r}
# Geometric Distribution
x <- base::seq(0,20,1) # Different values of R
prob <- 1/(1.630)
geome_data <- base::data.frame(x, probg = dgeom(x, prob))

ggplot(data = geome_data, aes(x = x, y = probg)) +
  geom_bar(stat = "identity") +
  labs(y = "Probability", x = "Secondary Cases",
       title = "Geometric Distribution")
```

Under the geometric distribution, there is a higher probability that a primary case can transmit the virus, as the probability of a primary case generating 1, 2, or more secondary cases is higher with this model compared to the negative binomial model.
:::

**Continuous Models**

**Uniform Distribution**

The uniform distribution models a continuous variable that takes values within an interval $[a,b]$ with equal probability. This distribution is often used in the simulation of random numbers. If $X$ follows a uniform distribution, it is represented as:

$X ∼U(a,b)$

Its parameters a and b represent the minimum and maximum values that the variable can take, respectively. Its density function is determined by:

$f(x)=\frac{1}{b-a}$,with $a<x<b$

The mean and variance are determined by:

$E(x)=\frac{a+b}{2}$ and $V(x)=\frac{(b-a)^2}{12}$

::: challenge
**Example**

A researcher wants to simulate the behavior of COVID-19 and needs to randomly generate the value that the basic reproduction number $R_0$ can take to use it in their propagation model. To do this, they assume that the $R_0$ of COVID-19 follows a uniform distribution between 2 and 5:

$R0∼U[2,5]$

For their simulation, they need to generate five possible values of $R_0$ with equal probability, which can be done in `R` using the following code:

```{r}
# Generating random numbers with the uniform distribution
n <- 5
a <- 2
b <- 5
stats::runif(n, a, b)
```
:::

**Normal Distribution**

The normal distribution is undoubtedly the most important probabilistic model in statistical theory because it allows modeling multiple real-life problems and its significant role in the field of inference. This distribution attempts to model continuous variables that can be influenced by multiple factors, whose effects, when summed, cause the values of the distribution to tend towards the center (mean). For example, body temperature may follow a normal distribution because it is influenced by multiple biological and environmental factors, which, when their effects are summed, cause most individuals to be around a central value.

To mathematically express that a continuous variable has a normal distribution, it is written as:

$X ∼N(μ,σ)$

It will have the following probability density function:

$f(x)=\frac{1}{ σ\sqrt{2\pi}}exp[-\frac{1}{2 σ^2}(x-u)^2]$

Where $μ$ and $σ$ are the parameters of the distribution and represent, respectively, the mean and standard deviation of the random variable, that is, the central value and the dispersion of the data around it. These parameters correspond to the values that would be obtained if the entire population were studied and not just a sample of it.

When $μ=0$ and $σ=1$, it is called the **standard normal distribution**. However, there are many normal distributions depending on the values of their parameters, but regardless of these values, the shape of the distribution is always **symmetric** and can always be transformed into a standard normal distribution by applying a standardization procedure using the following formula:

$Z=\frac{X-μ}{σ}∼N(0,1)$

::: challenge
**Example**,

If it is known that in a community, the age of COVID-19 cases who died follows a normal distribution with a mean of 67.8 and a standard deviation of 15.4 years. What is the probability that a deceased person is younger than 40 years?

First, define the variable to be studied, which has a normal distribution

$X∼N(67.8,15.4)$

$X$: The age of COVID-19 cases who died

In R, we can use the `pnorm()` function as follows to find:

$P(X<40)=?$

```{r}
mu <- 67.8
sigma <- 15.4 
x <- 40 
stats::pnorm(x, mean = mu, sd = sigma)
```

Therefore, the probability that a deceased person from COVID-19 is younger than 40 years is 3.5%.
:::

**Log-normal Distribution**

The log-normal distribution arises when considering continuous random variables that do not take the value of zero or negative numbers, whose distribution has an asymmetric shape, and their variation is generated by multiple factors whose effects are not symmetric. If a r.v. follows a log-normal distribution, its transformation by applying the logarithm function will generate a normal variable, hence its name. In the field of infectious diseases, the log-normal distribution is widely used to model incubation periods (time from infection to symptom onset).

If $X ∼LogN(μ,σ)$, then, it is satisfied that $Y=log (X) ∼N(μ,σ)$, and the density function of $X$ is given by:

$f(x)=\frac{1}{ xσ\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{ln(x)-u}{σ})^2}$

Unlike the normal distribution, in the log-normal distribution, the parameter μ acts as a scale parameter, increasing the dispersion of the data as its degree of amplitude increases, and the parameter σ controls the shape, that is, the degree of asymmetry.

::: challenge
**Example**

In 2009, in the study by Lessler et al., the incubation periods of various pathogens were modeled using a log-normal distribution. The main interest was to estimate the parameters $(μ,σ)$. For example, in the case of SARS, an estimate of $μ=0.660$ and $σ=1.205$ was found, which implies that, on average, an infected case develops symptoms in 0.7 days. This information can be obtained in the `epiparameter` package with the following command:

```{r}
SARS_incubation <- epiparameter::epiparameter_db(
    disease = "SARS",
    epi_name = "incubation period",
    single_epiparameter = TRUE
)
SARS_incubation
```

The complete distribution of the incubation period for SARS can be graphed using:

```{r}
plot(SARS_incubation)
```

The above is useful for answering questions like: What is the probability that a SARS case will develop symptoms two days after infection?

```{r}
stats::plnorm(2, meanlog = 0.660, sdlog = 1.205, lower.tail = FALSE)
```
:::

**Gamma Distribution**

When studying Poisson random variables, we are generally interested in studying the number of events that occur with a mean $λ$ over a defined time interval. The Gamma distribution focuses on studying the r.v. $X$: the time that elapses until a certain number of events $α^th$ occur. For example, if we are evaluating the number of infections per hour and want to study how long it may take to observe α infections, graphically $X$ corresponds to:

![](fig/gamma.png)

The Gamma distribution is widely used in survival analysis due to its flexibility, which is given by its shape parameters $α$ and scale $θ$, which determine its density function, which has an asymmetric behavior. Here, $θ$ represents the average waiting time until the first event occurs, and $α$ is the number of events expected to occur. This distribution is denoted as follows:

$X ∼Gamma(α,θ)$

$f(x)=\frac{1}{(α-1)!θ^α}e^{\frac{-x}{θ}} x^{α-1}$

$E(x)=αθ$

$Var(x)=αθ^2$

When $θ$ increases in value, the concentration of probability shifts to the right, and the same occurs when expecting a higher number of events $α$, as the waiting time $X$ may be longer.

::: challenge
**Example**

A possible application of the Gamma distribution is in modeling the serial interval of infectious diseases. The serial interval (s) is defined as the time that elapses between the onset of symptoms in the primary case and the onset of symptoms in the secondary case. In the study by Ghani et al., the serial interval distribution of Influenza *Influenza-A-H1N1Pdm* was described using the Gamma distribution, finding the following parameters:

$s ∼Gamma( α=2.622,θ=0.957)$

This information can also be obtained in the `epiparameter` package with the following command:

```{r}
influenza_s <- epiparameter::epiparameter_db(
  disease = "Influenza",
  epi_name = "serial_interval",
  single_epiparameter = TRUE
)
influenza_s
```

```{r}
graphics::plot(influenza_s)
```

With this information, it would be possible to find the mean and standard deviation of the distribution based on the application of the Gamma distribution:

```{r}
shape <- 2.622
scale <- 0.957
mean <- shape*scale
sd <- sqrt(shape*scale^2)
print(c(mean, sd))
```

Therefore, the average serial interval of influenza is 5.51 days with a standard deviation of 1.55 days.
:::

**Weibull Distribution**

Like the Gamma distribution, the Weibull distribution is useful in analyzing r.v.s that represent waiting times until a particular event occurs. The Weibull distribution has two parameters, and its density function is defined by:

$f(x)= \frac{β}{η}(\frac{x}{η})^{β-1}{e^{-(x/η)}}^β$

Here, $η$ is the scale parameter, and $β$ is the shape parameter. The shape parameter $β$ is also known as the slope and attempts to model the relationship between probability and waiting times. Thus, when $β>1$, the event occurrence rate increases over time, while if $β<1$, it describes that the event risk decreases over time. The scale parameter controls the degree of variability of the distribution and is in the same units as $X$.

::: challenge
**Example**

In the study by Virlogeux et al., the incubation period of influenza was described using the Weibull distribution, finding the following parameters:

$x∼Gamma( β=2.101,η=3.839)$

This information can also be obtained in the `epiparameter` package with the following command:

```{r}

influenza_incubation <- epiparameter::epiparameter_db(
  disease = "Influenza",
  epi_name = "incubation period",
  single_epiparameter = TRUE
)
influenza_incubation

```

```{r}
plot(influenza_incubation)
```
:::
   
<center>  
   
[![](fig/dudas.png){width="100"}](https://epiverse-trace.github.io/epitkit/Banco_errores.html)  
  
</center>
  
## **Topic 5: Introduction to Statistical Inference**

Statistics can be divided into two main branches: descriptive and inferential. As we saw in previous units, the first generally seeks to summarize and explore the data collected in a sample selected from a population. In contrast, the second aims to make generalizations and conclusions about the entire population based on information or data from a sample.

Due to the nature of the inferential process, which is based on random sampling from the population, an estimator can take multiple values as it depends on the units selected in the sample. This variation due to chance, known as **sampling variation**, must be considered in the inference process, as we will see later.

It is important to emphasize that sampling variation depends on the sample size. For example, if we take samples of size 10 and calculate the CFR in each of them, these estimates will be more similar to each other compared to those obtained when selecting only 5 individuals per sample. The above can be verified by performing a simulation in R and selecting 1000 samples of size 5 and 10, respectively. As shown in the following figure, the CFR estimates increased the sample size from 5 to 10 were more similar with a smaller IQR.

```{r}
library(infer)
set.seed(200)
population <- base::data.frame(muerto=c(base::rep(1,40), base::rep(0,160)))
samplesn5 <- population %>%
  infer::rep_sample_n(size = 5, reps = 100, replace = FALSE)

cfrn5 <-samplesn5 %>%
  dplyr::group_by(replicate) %>%
  dplyr::summarise(cfr = mean(muerto))

samplesn10 <- population %>%
  infer::rep_sample_n(size = 10, reps = 100, replace = FALSE)

cfrn10<-samplesn10 %>%
  dplyr::group_by(replicate) %>%
  dplyr::summarise(cfr = mean(muerto))

cfr <- dplyr::bind_rows(cfrn5, cfrn10)
cfr <- cfr %>% 
  dplyr::mutate(size = base::as.factor(c(base::rep(5,100), base::rep(10, 100))))


# Plot sampling distribution
ggplot(cfr, aes(x =size, y=cfr, fill=size)) +
  geom_boxplot(show.legend = FALSE) +
  labs(x = "Sample Size", y = "CFR Estimate",
       title = " ") + scale_fill_brewer(palette="Blues")

```

If we calculate the mean and standard deviation of the estimated CFR values with samples of size 5 and size 10, we see that the standard deviation of the estimates is lower when increasing the sample size, but in both cases, on average, the samples approached the true parameter value of 0.20.

```{r}
cfr %>%
  group_by(size) %>%
  summarise(
    mean = mean(cfr),
    sd = sd(cfr),
    median = median(cfr),
    P25 = quantile(cfr, 0.25),
    P75 = quantile(cfr, 0.75)
  )
```

However, if in real life we can only take one random sample, this means we will only have one opportunity to calculate a statistic that will be the **point estimator** of the parameter. Nevertheless, that single value will not provide information about the variability inherent in the random selection of the sample. Additionally, as we saw in the previous example, there is a high probability that many possible sample configurations will yield estimates that are far from the true parameter value. Therefore, we must attempt to incorporate sampling variability into the estimation process.

**Confidence Interval Estimation**

The goal of confidence interval estimation is to provide a range of values, a lower and upper limit (a; b), that with high probability "**confidence**" contains the true value of the parameter to be estimated. Although different limits would be obtained with each random sample that could be selected, this procedure ensures that a determined $(1-α) \%$ of the constructed intervals will contain the true parameter value. The above also implies that an $α\%$ of the intervals will not contain the true value. The symbol α is known as the significance level.

In general, a confidence interval is constructed with the following ingredients:

$\text{Estimator} ±(\text{reliability coefficient})*(\text{standard error})$

::: challenge
**Example**

In the CFR package of the Epiverse-TRACE initiative, information is available on an Ebola outbreak that occurred in 1976 in Zaire, now called the Republic of Congo, documenting the number of cases and deaths over 73 days. Finally, 245 Ebola cases were reported, and of these, 234 were fatal cases. If the interest is to perform a confidence interval estimation of the CFR at 95%, what should be the procedure?

●       [**Step 1-Estimator**]{.underline}: start by finding the estimate in the observed sample:

$\hat{p} = \widehat{\text{CFR}} = \frac{234}{245}= 0.955$

Therefore, the estimated CFR was 95.5%

●       [**Step 2-Reliability Coefficient**]{.underline} based on the normal distribution for 95% confidence would be 1.96

●       [**Step 3-Standard Error:**]{.underline}

$\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}=\sqrt{\frac{0.955 (1-0.955)}{245}}$

●       [**Step 4-Put the ingredients together**]{.underline}

As you have noticed so far, this step-by-step process can be cumbersome due to the calculations, but in R, we can obtain everything more quickly and efficiently as follows:

${\left[p ̂±z_{\frac{α}{2}} \sqrt{\frac{p ̂(1-p ̂)}{n}}\right]}={\left[0.955±1,96\sqrt{\frac{0.955 (1-0.955)}{245}}\right]}$

As you have noticed so far, this step-by-step process can be cumbersome due to the calculations, but in R, we can obtain everything more quickly and efficiently as follows:

```{r}
#Load the cfr library
library(cfr)
# Load the Ebola 1976 data 
utils::data(ebola1976)
ebola1976%>%  dplyr::summarise(
    n=sum(cases), #Total cases
    deaths = sum(deaths), #Total deaths
    cfr_est = deaths/n, # Estimate 
    error = sqrt((cfr_est*(1-cfr_est))/n),
    lim_inf = cfr_est -1.96*error, #Lower limit of CI
    lim_sup = cfr_est +1.96*error #Upper limit of CI
) 
```
:::

Finally, we can conclude that with 95% confidence, the CFR of Ebola in the 1976 epidemic in the Democratic Republic of Congo is contained in the interval between 92.9% and 98.1%.

The CFR package also has a built-in function to automatically estimate the CFR during an epidemic with its respective 95% confidence interval using the function:

```{r}
cfr::cfr_static(data = ebola1976)
```

As you can see, there are slight differences between the CI constructed step-by-step and the one reported by the `cfr_static` function. This is because the CFR package constructs the CI using the maximum likelihood method and different statistical distributions depending on the total number of cases, but the interpretation does not change.
  
<center>  
   
[![](fig/dudas.png){width="100"}](https://epiverse-trace.github.io/epitkit/Banco_errores.html)  
  
</center>
   
::: keypoints
**At the end of the session, check if you have achieved the objectives:**

-   Understand the role of statistics in the study of infectious diseases.

-   Understand statistical measures to summarize and analyze information.

-   Familiarize yourself with the concept of a random variable and recognize the main probability distributions.

-   Identify and understand the process of the statistical problem as an inference problem from a sample.

-   Understand the concept of confidence interval and the procedure of hypothesis testing.
:::

### Contributions

-   Erika Cantor: Initial version
-   Zulma M. Cucunuba: Editing
-   Laura Gómez-Bermeo: Editing
-   Andree Valle-Campo: Minor edits
-   José M. Velasco-España: Minor edits
